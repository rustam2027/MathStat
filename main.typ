#import "header.typ": template, definition, theorem, property, corollary, arr
#import "questions.typ": question

#show: doc => template(doc)

#outline()

#question(1)[
  #definition([Случайная величина])[
    измеримое отображение $xi: (Omega, cal(F)) -> (RR, cal(B))$,
    где $cal(B)$ --- борелевская $sigma$-алгебра.
    ($xi$ измеримо, если $xi^(-1) (B) in cal(F)$ для каждого $B in cal(B)$)
  ]

  #definition([Функция распределение случайной величины])[
    функция $F_xi (t) = P(xi < t)$
  ]

  #property([свойства функций распределения])[
    + $x < y$ $=>$ $F_xi (x) <= F_xi (y)$
    + $display(lim_(x->-oo) F_xi (x) = 0)$, $display(lim_(x -> +oo) F_xi (x) = 1)$
    + $F_xi (t - 0) = F_xi (t)$
  ]
]
#question(2)[
  #table(columns: (1fr, 1fr), align: center + horizon ,table.header([*название*], [*вероятнось*]))[
   Нормальное, $N_(alpha, sigma^2)$
  ][$ 1/sqrt(2 pi sigma^2) e^(-(y - alpha)^2 / (2 sigma^2)) $][
    Бернулли, $B_p$
  ][$ P{xi = 0} = 1 - p \ P{xi = 1} = p $][
   Пуассона, $product_lambda$
  ][$ lambda^k / k! e^(-lambda) $][
    Равномерное, $U_(a, b)$
  ][
    $ cases(0", " y in [a, b], 1/(b - a)", " y in.not [a, b]) $
  ]

  #property([нормальное распределение])[
    + Устойчивость по суммированию: $xi ~ N_(alpha_1, sigma_1)$, $eta ~ N_(alpha_2, sigma_2)$, $xi + eta ~ N_(alpha_1 + alpha_2, sigma_1 + sigma_2)$
    + Моменты: $ EE[X^p] = cases(0", " p = 2n + 1, sigma^p (p - 1)!!", " p = 2n) $
  ]

  #property([распредедение Бернулли])[
    + Моменты: $EE[X^n] = EE[X] = p$
  ]

  #property([распределение Пуассона])[
    + Моменты: $EE[X] = lambda$, $D[X] = lambda$
    + Устойчивость по суммированию: $xi_i ~ product_lambda_i => sum xi_i ~ product_(sum lambda_i)$
  ]

  #property([равномерное распределение])[
    + Моменты: $EE[X] = (a + b)/2$, $D[X] = (b - a)^2 / 12$
  ]

  #property([хи-квадрат])[
    + Определение: $x = z_1^2 + ... + z_n^2$, $z_i ~ N_(0, 1)$, $x ~ chi^2_n$
    + Устойчиво относительно суммирования
    + Моменты: $EE[X] = k$, $D[X] = 2k$
    + Получение из нестандартных: $display(x = sum_(i=1)^n ((z_1 - alpha) / sigma)^2)$, $z_i ~ N_(alpha, sigma^2)$, $x ~ chi^2_n$
    + Следствия леммы Фишера:
      - $n S^2 = (n - 1) S^2_0 ~ chi^2_(n-1)$, если $x_i ~ N_(0, 1)$
      - $display((n S^2) / sigma^2 ~ chi^2_(n - 1))$
  ]

  #property([распределение Стьюдента])[
    + Определение: $display(t = z / sqrt(y / k))$, где $z ~ N_(0, 1)$, $y ~ chi^2_k$, $t ~ T_k$
  ]

  #property([распределение Фишера])[
    + Определеие: $display(F_(d_1, d_2) = (Y_1 \/ d_1) / (Y_2 \/ d_2))$, где $Y_i ~ chi^2_d_i$
  ]

  #property([распределение Колмогорова])[
    + Функция распределения:
      $ K(t) = cases(sum_(k=-oo)^(+oo) (-1)^k e^(-2 k^2 t^2) ", где" t > 0, 0 ", где" t <= 0) $
      
  ]
]
#question(3)[
  #definition([Сходимость почти наверное])[$xi_n -> xi$ _почти наверное_,
  если $xi_n (w) -> xi (w)$ $forall w in A_0$,
  $A_0 = {w: xi_m (w) -> xi (w)}$ имеет полную меру. То есть $ P({w: xi_m (w) -> xi (w)}) = 1 $]

  #definition([Сходимость по вероятности])[$xi_n -> xi$ _по вероятности_, если $forall epsilon > 0$
  $ lim_(n -> oo) P(|xi_n - xi| > epsilon) = 0 $]

  #property([сходимости по вероятности])[
    + $xi_n arr_p c$, $g in C$, при $x = c$, тогда $g(xi_n) arr_p g(c)$
    + $xi_n arr_p xi$, $g in C$, то $g(xi_n) arr_p g(xi)$
    + $xi_n arr_p xi$, и $xi_n$ монотонна, т.е. $P{w | xi_n (w) <= xi_(n + 1) (w)} = 1$, тогда $xi_n arr_"п.н." xi$
  ]

  #definition([Сходимость по распределению])[$xi_n -> xi$, _сходятся по распределению_ ($xi_n => xi$),
  если $F_xi_n (t) -> F_xi (t)$ поточечно для всех точек непрерывности предельной функции $F_xi (t)$]

  Из сходимости почти наверное следует сходимость по вероятности,
  а из нее следует сходимость по распределению.
  $ "п.н." -> "p" -> => $

]
#question(4)[
  #theorem("ЦПТ")[
    $xi_1, ..., xi_n$ --- н.о.р., $0 < D xi_i < oo$, тогда $display((S_n - n EE xi_1) / sqrt(n D xi_1)) => eta ~ N_(0, 1)$
  ]
]
#question(5)[
  #theorem("Закон больших чисел в форме Чебышева")[
    Пусть $xi_i$ --- н.о.р., $EE |xi_1|< oo$, тогда $S_n / n arr_p EE xi_1$, где $S_n = xi_1 + ... + xi_n$
  ]

  #theorem("Закон больших чисел")[
    Говорят что последовательность случайных величин, с конечными первыми моментами,
    удовлетворяет закону больших чисел, если:
    $ (S_n - sum EE xi_i) / n -> 0 $
  ]
]
#question(6)[

  Исходными данными в математической статистике являются конечные наборы результатов уже проведенных в одних и тех же условиях стохастических экспериментов.

  При этом распределение отдельного эксперимента $P(A) = P(xi_1 in A)$ предполагается неизвестным частично или полностью. 
  
  Задача математической статистики как раз и состоит в восстановлении (или оценке) распределения $P(dot)$ как можно более
  точно.

  #definition([Выборка объема n])[
    Вектор $X = (x_1, . . . , x_n)$ называется выборкой объема $n$ из неизвестного распределения.
    Декартова степень $frak(X)^n$ с соответствующей $sigma$-алгеброй подмножеств называется выборочным пространством.
    При этом, выборка --- не случайный вектор.
  ]

  #definition([Эмпирическое распределение])[
    Эмпирическое распределение, построенное по выборке объема $n$:
    $ P^*_n (A) = (\#{x_i | x_i in A}) / n $
    
    Легко видеть, что $P^∗_n$ – дискретная вероятностная мера с атомами в точках $ {x_i; i <= n} $ и равными массами $1/n$.
  ]


  #definition([Эмпирическая функция распределение])[
    Пусть $(x_1, ..., x_n) in RR$. Эмпирической функцией распределения $F^∗_n (t)$, построенной по выборке объема n, называется функция $F^∗_n (t) = P^*_n (-oo, t)$. Таким образом, $F^*_n$ – это доля выборочных наблюдений, попавших строго левее точки t.
    
    Если упорядочить все элементы выборки $(x_1, ..., x_n)$ в порядке возрастания, то получится новая последовательность – вариационный ряд: $x_((1)) <= ... <= x_((n))$. Случайная величина $x_((k))$ называется k-й _порядковой статистикой_.

  ]

  #theorem([Гливенко-Кантели])[
    Пусть $x_1 in (frak(X), cal(B))$, и $cal(A) subset cal(B)$ - класс измеримых подмножеств. Будем говорить, что для класса $cal(A)$ выполняется теорема Гливенко – Кантелли, если 
    $ sup_(A in cal(A)) |P^∗_n (A) − cal(P)_x_1 (A)| arr_"п.н." 0 "при n" -> oo $
  ]

  #theorem([классическая теорема Гливенко-Кантели])[
    Для любой функции распределения $F_x_1$ наблюдаемой случайной величины 
    $ sup_(t in RR) abs(F^∗_n (A) − F_x_1 (A)) arr_"п.н." 0 "при n" -> oo $

  ]
]
#question(7)[
  #definition([Выборочная характеристика])[
    _выборочной характеристикой_ называется измеримый k-мерный (принимающий значения в пространстве $RR^k$) функционал $G(P^∗_n)$.
  ]

  #definition([Параметр])[
    параметром наблюдаемого распределения называется значение того или иного функционала от этого распределения: $Theta = G(cal(P)_x_1) in RR^k", где" cal(P)_x_1 (A) = P(x_1 in A)$.
  ]

  #definition([Параметрическое семейство распределений])[
    Параметрическое семейство распределений ${cal(P)_theta}_{theta in Theta}$ – это класс распределений известной функциональной формы, содержащей один или несколько скалярных параметров. При этом множество Θ называется параметрическим.
  ]


  #definition([Оценка неизвестного параметра])[
    Оценка $θ^∗_n = θ^∗_n (x_1, ..., x_n)$ неизвестного параметра $Theta$ – это выборочная характеристика $θ^∗_n = G(P^∗_n)$, которая в том или ином смысле приближает неизвестный параметр $Theta$.
  ]

  #definition([Состоятельность оценки])[
    Оценка $θ^∗_n$ называется состоятельной, если $ θ^∗_n arr_p theta "при" n -> oo $
  ]

  #definition([Сильная состоятельность оценки])[
    Оценка $θ^∗_n$ называется сильно состоятельной, если $ θ^∗_n arr_"п.н." theta "при" n -> oo $
  ]

  #definition([Несмещённые оценки])[
    Оценка называется несмещенной, если $EE theta^*_n = theta $ для $forall theta in Theta$. Если $theta^*_n = theta + b_n (theta)$, то оценка называется смещенной, а $b_n$ – ее смещением.
    
    Для несмещенной оценки $delta_(theta^*_n) =  DD theta^*_n$,
    где $delta_(theta^*_n) = EE_theta (theta^*_n - theta)^2$ --- функция потерь.
    
    $EE_theta$ обозначает математическое ожидание, вычисленное при условии, что $theta$ – истинное значение параметра наблюдаемого распределени.]


    *Пример* 
    - $theta^∗_n = 2overline(X)$ --- несмещенная оценка для распредления $U_(0,theta)$.
    
    - $theta^∗_n = X_((n))$ --- смещенная оценка для распредления $U_(0,theta)$.

  Знание моментов распределения также многое может сказать о его виде и свойствах. Введем выборочные аналоги неизвестных истинных моментов распределения. 

  #definition([Выборочные моменты])[

    Выборочные моменты в математической статистике — это оценка теоретических моментов распределения на основе выборки. 

    #table(
      columns: (1fr, 1fr),
      align: center + horizon,
      inset: 10pt,
      table.header([Теоретические характеристики], [Эмпирические характеристики]),
      
      [$ E xi = E X_1 = a $], 
      [$ overline(X) = 1/n display(sum)^n_(i=1)X_i $],

      [$ D xi = D X_1 = sigma^2 $], 
      [$ S^2 = overline(X^2) - overline(X) =  1/n display(sum)^n_(i=1)(X_i - overline(X))^2 $ 

      $ S^2_0 = n/(n-1) S^2 = 1/(n - 1) display(sum)^n_(i=1)(X_i - overline(X))^2 $

      $ S^2_1 = 1/n display(sum)^n_(i=1)(X_i - E X_1)^2 $],
      
      [$ E xi^k = E X^k_1 = m_k $], 
      [$ overline(X^k) = 1/n display(sum)^n_(i=1)X^k_i  $],
    )

    Список числовых характеристик и их оценок можно продолжать, рассмотрев:
    - выборочное среднее : $overline(g(x)) = 1/n display(sum)^n_(i=1) g(X_i)$

    - k-ый выборочный момент $1/n display(sum)^n_(i=1) X_i ^k$

    - центральный момент $1/n display(sum)^n_(i=1)(X_i - overline(X))^k$

    - абсолютный момент $1/n display(sum)^n_(i=1)|X_i|$

  ]
]
#question(8)[
  #theorem([Лемма Фишера])[
    Пусть $X$ – стандартный нормальный вектор, а $C = norm(c_"ij") n times n$ – ортогональная матрица. Тогда $Y = X C$ является стандартным нормальным вектором.
  ]

  #corollary([1])[
    Пусть выполнены условия леммы Фишера и $r < n$. Тогда квадратичная форма $Q(X) = display(sum^n_(i=1)) x^2_i - y^2_1 - ... - y^2_r $ не зависит от случайного вектора $(y_1, ..., y_r)$ и имеет распределение $chi^2$ с $n − r$ степенями свободы.
  ]

  #corollary([2])[
    $n S^2 = (n-1) S^2_0 ~ chi^2_(n-1)$, если $X_i ~ N_(0,1)$
  ]

  #corollary([3])[
    Пусть $X$ – выборочный вектор из распределения $N_(alpha, sigma)$. Тогда
      + $(n S^2)/ sigma^2 ~ chi^2_(n-1)$;
      + случайные величины $S^2$ и $overline(X)$ независимы.
  ]
]
#question(9)[
  #definition([Доверительный интервал])[
    Пара упорядоченных статистик $(theta^(-)_n (X), theta^(+)_n (X))$ называется доверительным интервалом уровня доверия $1 − epsilon$ (иногда говорят уровня $epsilon$), если при всех объемах наблюдений справедлива следующая оценка вероятности покрытия случайным интервалом неизвестного параметра:

    $ P(theta^(-)_n (X) < theta < theta^(+)_n (X)) >= 1 - epsilon $

    При знаке равенства получаем минимальный доверительный интервал.
  ]

  #definition([Точный доверительный интервал])[
    В определении доверительного интервала в неравенстве достигается равенство:
    $ P(theta^(-)_n (X) < theta < theta^(+)_n (X)) = 1 - epsilon $
  ]

  #definition([Асимптотический доверительный интервал])[
    Пара упорядоченных статистик $(theta^(-)_n (X), theta^(+)_n (X))$ называется асимптотическим доверительным интервалом уровня доверия $1 − epsilon$:

    $ display(#math.op($underline(lim)$, limits: true)_(n->oo)) P(theta^(-)_n (X) < theta < theta^(+)_n (X)) >= 1 - epsilon $
  ]

]
#question(10)[

  Для пострения *точного доверительного интервала* обычно используется следующий подход:

  + Пусть для данного параметрического семейства $F_theta$ существует функционал $G(theta, X)$, распределение которого не зависит от $theta$.

  + Причем функционал $G(theta, X)$ имеет строгую монотонность одного знака по $theta$ для всевозможных значениях выборки и непрерывен по параметру. 
  
  + Тогда для наперед заданного $epsilon > 0$ пара (неупорядоченная) чисел ${G^(−1)(t^((1))_epsilon , X), G^(−1)(t^((2))_epsilon , X)}$ с условием $ P(t^((1))_ε < G(theta, X) < t^((2))_ε ) = 1 − ε $ образует доверительный интервал уровня $1 - epsilon$, где $G^(−1)(t, X)$ – обратная функция по первому аргументу.

    При этом значения  $t^((1))_epsilon, t^((2))_epsilon$, вообще говоря находятся не однозначно.


  При значительных объемах наблюдений можно использовать *асимптотический подход*, который по сути сводит рассматриваемую задачу к нормальным выборкам.

  #theorem([Построение АДИ с помощью АНО])[Пусть $theta^*_n$ – произвольная асимптотически нормальная оценка для параметра $theta$, т. е. $sqrt(n)(theta^*_n - theta) => eta in N_(0, sigma)$, где коэффициент рассеивания $sigma(theta)$ непрерывен. Тогда асимптотические доверительные границы определяются по формулам

  $ theta^plus.minus = theta^*_n plus.minus (t_epsilon sigma(theta^*_n))/sqrt(n) $
  где $t_(1 - epsilon/2) = t_epsilon$ --- квантиль уровня $1 - epsilon/2$ станд. норм. распр., при этом, по свойству функции Ф, имеем $Ф(-t_epsilon) = Ф(t_(epsilon/2)) =  epsilon/2$.]

  Отсюда получаем алгоритм:
  + выбираем функционал $G(theta, X)$ --- аналогично, не зависящий по распредлению от параметра $theta$. X --- статистика. Берем $ G(theta, X) = (sqrt(n)(theta^*_n - theta))/sigma(theta^*_n) = sigma(theta)/sigma(theta^*_n) (sqrt(n)(theta^*_n - theta))/sigma(theta) => eta ~ N_(0, 1) $ (либо другой, предельное значение которого не зависит от параметра $theta$).

  + В силу ЦПТ: $ P(-t_epsilon < G(theta, X) < t_epsilon) approx P(-t_epsilon < eta < t_epsilon) = \ Ф(-t_epsilon) - Ф(t_epsilon) = 1 - 2 Ф(-t_epsilon) = 1 - epsilon $
    Решаем неравенство $-t_epsilon < G(theta, X) < t_epsilon$, получаем асимптотически доверительные интервалы.
     

]
#pagebreak()
#question(11)[
  *Построение доверительного интервала для дисперсии (неизвестно $alpha$):*

  Пусть $G (sigma) = (n S^2)/ (sigma ^ 2)$. Тогда по теореме о построении доверительных интервалов необходимо найти числа $t_epsilon^(1), t_epsilon^(2): P (t_epsilon^(1) < G(sigma) <  t_epsilon^(2)) = 1 -epsilon.$ Обычно для определения границ используются:
  $ P(G(sigma) < t_epsilon^(1)) = epsilon / 2;  P(G(sigma) < t_epsilon^(2)) = 1 - epsilon / 2 $

  Для нахождения  $t_epsilon^(1), t_epsilon^(2)$ используется таблица распределения $chi^2_(n - 1)$
  
   $ (sigma^2_n)^- =( n S^2) / t_(1-epsilon/2); (sigma^2_n)^+ =(n S^2 )/ t_(epsilon/2) $



    где $t_(1-epsilon/2),t_(epsilon/2)$ - квантили уровня $1-epsilon/2,epsilon/2$ распределения $chi^2_(n-1)$

  *Построение доверительных границ для среднего (неизвестно $sigma^2$)*

  Рассмотрим функционал $ G(alpha, X) = sqrt(n) (overline(x) - alpha) / S_0 $
  $G(alpha, X) in T_(n - 1)$. Пусть $tau_epsilon$ -- квантиль уровня $1 - epsilon / 2$ распределения $T_(n-1).$ Тогда:
  $ alpha_n^- = overline(x) - (S_0 tau_epsilon) / sqrt(n); " " alpha_n^+= overline(x) + (S_0 tau_epsilon) / sqrt(n) $
]
#question(12)[
  #definition[Гипотеза][
    некоторое суждение о распределении. Обозначается: $H_i$ 
  ]

  #definition[Простая и сложная гипотеза][
    $H_i$ -- простая, если она однозначно восстанавливает распределение, иначе сложная
  ]
  *Пример:*
    _Простые:_\
    $H_1 = {X_1 ~ N_(0,1)}$\
    $H_2 = {X_1 ~ E_3}$\
    _Сложные:_\
    $H_3 = {X_1 ~ Pi_lambda, lambda > 0}$\
    $H_4 = {X_1 ~ X_1 - "дискретная"}$
  

  #definition[Критерий][
    $ delta(overline(x)) = cases(H_1 ", " in A, H_2 ", " S(arrow(X)) in.not A  ) $
    
  ]

  #definition[Размер][
    $alpha_1 = alpha = epsilon = P_(H_i) (delta(overline(X)) eq.not H_i), " " i = 1, 2 $ 
  ]

  #definition[Вероятность ошибки $i$-го рода][
    $alpha_i = P_(H_i) (delta(overline(X)) eq.not H_i), " " i = 1, 2 $ 
  ]

  #definition[Мощность критерия из лекций][функция $beta_delta (theta) = 1 - alpha_theta (delta)$]


  #definition[Мощность критерия из семинаров][функция $beta = 1 - alpha_2 = P_(H_2) (delta(overline(X)) = H_2)$]

  #definition[Состоятельность][
    Критерий состоятельный, если $beta arrow.long 1$
  ]

]
#question(13)[
  #definition[Аналог ошибки второго рода][
    $alpha_theta (delta) = P_theta (delta eq.not theta)$
  ]
  #definition[Мощность критерия][функция $beta_delta (theta) = 1 - alpha_theta (delta)$]

  #definition[НМК (Наиболее Мощный Критерий)][Если в некотором классе критериев существуем критерий $delta^*$ имеющий максимальную мощность при всех возможных значениях параметра, то $delta^*$ называется (равномерно) наиболее мощным в указанном классе]

  #theorem[Неймана-Пирсона][
    Пусть $H_1, H_2$ -- простые гипотезы, тогда НМК 
    $  delta(overline(X)) = cases(H_1 ", " psi_2 / psi_1 <= C_epsilon, H_2 ", " psi_2 / psi_1 > C_epsilon) $ где $C_epsilon$ получается из уравнения:
    $ P_(H_1) (psi_2/psi_1 > C_epsilon) = epsilon $
  ]
]
#question(14)[
  #theorem[Критерий Колмогорова][
  Пусть $X_1, ..., X_n$ -- н.о.р с непрерывной $cal(F)$. Тогда $ rho (overline(X)) = sqrt(n) sup_(t in RR) |F_n^*(t) - F(t)| arrow.double eta ~ K$ -- распределение Колмогорова.

  $ K(t) = cases(sum_(k =-oo)^(+oo) (-1) ^ k e ^ (-2 k^2 t^2)"при" t > 0, 0 "при" t <= 0 ) $
  ]

  Критерий Колмогорова асимптотического размера $epsilon$ отвергает основную гипотезу, если значение статистики $rho$ превосходит квантиль $tau_(1-epsilon)$ уровня 1 − $epsilon$ распределения Колмогорова

  #theorem[Критерий $chi^2$ Пирсона][
    Пусть $X_1, ..., X_n$ -- н.о.р. Тогда $ rho (overline(X)) = display(sum_(i = 1)^k (u_i - n p_i)^2 / (n p_i)) arrow.double eta ~ chi^2_(k-1) $ где ${Delta_i}_(i=1)^k$ -- разбиение $RR$, $u_i = display(sum_(j=1)^n I (X_j in Delta_i))$, $p_i = P_(H_i)(X_1 in Delta_i) > 0$. $k$ -- число интервалов.
  
    Критерий Пирсона асимптотического размера ε отвергает основную гипотезу, если значение статистики хи-квадрат $rho$ превосходит квантиль $tau_(1-epsilon)$ распредедения $chi^2_(k-1)$ с $k − 1$ степенью свободы.
  ]

]
#question(15)[

  #theorem[Критерий Фишера][
  Критерий Фишера используется для проверки простой гипотезы о равенстве дисперсий двух независимых нормальных выборок с одинаковым средним. Критерий Фишера основывается на статистике со структурой отношения $(xi_1^2 + ... + xi_n^2)/(overline(xi)_1^2 + ... + overline(xi)_m^2)$, где $xi_i, overline(xi)_j in N_(0,1)$ -- независимы в совокупности.

  $(xi_1^2 + ... + xi_n^2)/(overline(xi)_1^2 + ... + overline(xi)_m^2) ~ F_(n, m)$ -- распределение Фишера с параметрами n, m. В силу Леммы Фишера и уже проделанных элементарных преобразований получаем, что $(n S^2_x) / (m S^2_y) in F_(n - 1, m - 1)$ 
  
  
*Не с методички Борисова:*

Проверка гипотезы $H_1 = {sigma_1 = sigma_2}$.

Пусть даны две независимые выборки из нормальных распределений:
$overline(X) ~ N_(a_1, sigma^2_1)$ и  
$overline(Y) ~ N_(a_2, sigma^2_2)$,
средние которых, вообще говоря, неизвестны.

$ rho(overline(X), overline(Y)) =( S_0^2(overline(X))) / (S_0^2(overline(Y))) - "статистика Фишера" $


Возьмём квантиль $f_(1 - epsilon)$ распределения Фишера $F_(n-1, m-1)$.

Критерием Фишера называют критерий:

$
delta(overline(X), overline(Y)) = cases(
  H_1 "если" rho(overline(X), overline(Y)) < f_(1-epsilon),
  H_2 "если" rho(overline(X), overline(Y)) >= f_(1-epsilon).
)
$

При верной гипотезе $H_1$ величина $rho(overline(X), overline(Y))$ имеет распределение Фишера $F_(n-1, m-1)$ с $n - 1$ и $m - 1$ степенями свободы.
  ]
  #theorem[Критерий Стьюдента][
  Постановка задачи: $x_i in N_(alpha, sigma^2), N_(alpha_1, sigma^2), alpha, alpha_1$ -- неизвестны.

  Критерий Стьюдента проверяет сложную гипотезу $H = {alpha = alpha_1}$ против конкурирующей альтернативы. Этот критерий основан на статистике: 
  $ T = (overline(x) - overline(y)) / (sqrt(n S^2_x + m S^2_y)) dot sqrt((m+n-2)/ (1 / m + 1/n)) $

  которая имеет распределение Стьюдента с $n + m - 2$ степенями свободы, где $S^2$ -- выборочная дисперсия построенная по соответствующей выборке.
  
  $overline(x)$ и $S_x^2$ -- независимы по лемме Фишера. Аналогично для $y$. Т.к борелевские преобразования независимости не портят, то числитель не зависит от знаменателя. 

  $ (overline(x) - overline(y)) / sigma sqrt((n m) / (n+m)) in N_(0, 1), (n S^2_x + m S^2_y) / sigma ^ 2 in chi^2_(m+n - 2) $

  получаем вероятностную модель закона Стьюдента
  ] 
]
#question(16)[
  #definition([P-value])[в критериях согласия вероятность статистики критерия принять такое же или большее значение как значение случайной величины. 
  $ epsilon^* = 1 - F_eta (rho(overline(X))) = P(eta > rho ( overline(X)) ) $ 
  
  $rho(overline(X)) $ -- реализация статистики.

  Если p-value меньше заданного уровня значимости, то нулевая гипотеза отвергается в пользу альтернативной. В противном случае она принимается.] 
]
